&emsp;&emsp;Kafka属于分布式的消息引擎系统，它的主要功能是提供一套完备的消息发布与订阅解决方案。
在Kafka中，发布订阅的对象是主题（Topic），你可以为每一个业务，每个应用甚至是每类数据都创建专属的主题。


# Kafka体系结构
&emsp;&emsp;**Kafka的服务端：** 由被称为Broker的服务进程构成，即一个Kafka集群由多个Broker组成，Broker负责接收和处理客户端发送过来的请求，以及对消息进行持久化。
<br>
&emsp;&emsp;Kafka的客户端：
<br>
&emsp;&emsp;**Kafka的高可用：** 对数据进行备份，即把相同的数据拷贝在不同的多台机器上。Kafka定义了两类副本：领导者副本（Leader Replica）和追随者副本（Follower Replica）。领导者副本（Leader Replica）可以对外提供服务，这里的对外服务指的是与客户端程序进行交互；而追随者副本（Follower Replica）只是被动的追随领导者副本而已，不能与外界进行交互。（P.s.类似于MySQL的主从库，但是从库也是可以处理读请求的）。

## Kafka的三层消息架构：
- 第一层是主题层：每个主题可以配置M个分区，而每个分区又可以配置N个副本；
- 第二层是分区层：；
- 第三层是消息层：；

> 至此我们能够完整地串联起 Kafka 的三层消息架构：
第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。
第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。
第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。
最后，客户端程序只能与分区的领导者副本进行交互。
讲完了消息层次，我们来说说 Kafka Broker 是如何持久化数据的。总的来说，Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。不过如果你不停地向一个日志写入消息，最终也会耗尽所有的磁盘空间，因此 Kafka 必然要定期地删除消息以回收磁盘。怎么删除呢？简单来说就是通过日志段（Log Segment）机制。在 Kafka 底层，一个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。
这里再重点说说消费者。在专栏的第一期中我提到过两种消息模型，即点对点模型（Peer to Peer，P2P）和发布订阅模型。这里面的点对点指的是同一条消息只能被下游的一个消费者消费，其他消费者则不能染指。在 Kafka 中实现这种 P2P 模型的方法就是引入了消费者组（Consumer Group）。所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。为什么要引入消费者组呢？主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。我会在专栏的后面详细介绍消费者组机制，所以现在你只需要了解消费者组是做什么的即可。另外这里的消费者实例可以是运行消费者应用的进程，也可以是一个线程，它们都称为一个消费者实例（Consumer Instance）。
消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更酷的是它们还能彼此协助。假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。这个过程就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）。嗯，其实既是大名鼎鼎，也是臭名昭著，因为由重平衡引发的消费者问题比比皆是。事实上，目前很多重平衡的 Bug 社区都无力解决。
每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset）。注意，这和上面所说的位移完全不是一个概念。上面的“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。而消费者位移则不同，它可能是随时变化的，毕竟它是消费者消费进度的指示器嘛。另外每个消费者有着自己的消费者位移，因此一定要区分这两类位移的区别。我个人把消息在分区中的位移称为分区位移，而把消费者端的位移称为消费者位移。
小结
我来总结一下今天提到的所有名词术语：
消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。
主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。
分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。
消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。
副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。
生产者：Producer。向主题发布新消息的应用程序。
消费者：Consumer。从主题订阅新消息的应用程序。
消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。
消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。

最后我用一张图来展示上面提到的这些概念，希望这张图能够帮助你形象化地理解所有这些概念：
\\

# Kafka版本

> 应该选择哪种Kafka？
>> - **Apache Kafka：** 也称社区版 Kafka。优势在于迭代速度快，社区响应度高，使用它可以让你有更高的把控度；缺陷在于仅提供基础核心组件，缺失一些高级的特性。Apache Kafka是开发者人数最多、版本迭代速度最快的Kafka。如果你仅仅需要一个消息引擎系统抑或是简单的流处理应用场景，同时需要对系统有较大把控度，那么我推荐你使用Apache Kafka。
>> - **Confluent Kafka：** 目前分为免费版和企业版两种。企业版提供了很多功能，最有用的当属跨数据中心备份和集群监控。如果你需要用到Kafka的一些高级特性，那么推荐你是用Confluent Kafka。Confluent 公司提供的 Kafka。优势在于集成了很多高级特性且由 Kafka 原班人马打造，质量上有保证；缺陷在于相关文档资料不全，普及率较低，没有太多可供参考的范例。
>> - **CDH/HDP Kafka：** 如果你需要快速地搭建消息引擎系统，或者你需要搭建的是多框架构成的数据平台且Kafka只是其中一个组件，那么推荐你使用这些大数据云公司提供的Kafka。大数据云公司提供的 Kafka，内嵌 Apache Kafka。优势在于操作简单，节省运维成本；缺陷在于把控度低，演进速度较慢。

# 生产环境中Kafka集群部署方案
如果考虑操作系统与 Kafka 的适配性，Linux 系统显然要比其他两个特别是 Windows 系统更加适合部署 Kafka。虽然这个结论可能你不感到意外，但其中具体的原因你也一定要了解。主要是在下面这三个方面上，Linux 的表现更胜一筹。
I/O 模型的使用
数据网络传输效率
社区支持度
我分别来解释一下，首先来看 I/O 模型。什么是 I/O 模型呢？你可以近似地认为 I/O 模型就是操作系统执行 I/O 指令的方法。
主流的 I/O 模型通常有 5 种类型：阻塞式 I/O、非阻塞式 I/O、I/O 多路复用、信号驱动 I/O 和异步 I/O。每种 I/O 模型都有各自典型的使用场景，比如 Java 中 Socket 对象的阻塞模式和非阻塞模式就对应于前两种模型；而 Linux 中的系统调用 select 函数就属于 I/O 多路复用模型；大名鼎鼎的 epoll 系统调用则介于第三种和第四种模型之间；至于第五种模型，其实很少有 Linux 系统支持，反而是 Windows 系统提供了一个叫 IOCP 线程模型属于这一种。

说了这么多，I/O 模型与 Kafka 的关系又是什么呢？实际上 Kafka 客户端底层使用了 Java 的 selector，selector 在 Linux 上的实现机制是 epoll，而在 Windows 平台上的实现机制是 select。因此在这一点上将 Kafka 部署在 Linux 上是有优势的，因为能够获得更高效的 I/O 性能。

|  因素  |  考量点  |  建议  |
|:-:|:-:|:-:|
|  操作系统|  操作系统I/O模型|将Kafka部署在Linux系统上|
|  磁盘|  磁盘I/O性能|  普通环境使用机械硬盘，不需要搭建RAID|
|  磁盘容量  |  根据消息数，留存时间预估磁盘容量  |  实际使用中，<br>建议预留20% ~ 30%的磁盘空间|
|  带宽  |  根据实际带宽资源和业务SLA预估服务器数量  |  对于千兆网络，建议每台服务器按照700Mbps来计算，避免大流量下的丢包。|

# 最重要的集群参数
## 如何配置Broker端参数

> Broker端参数
>> - 与存储信息相关的参数：'log.dirs'和'log.dir'。
>> - 与Zookeeper相关的参数：'zookeeper.connect'。
>> - 与Broker连接数相关的参数：'listeners'、'advertised.listeners'和'host.name/port'。
>> - 关于Topic管理的参数：'auto.create.topics.enable'、'unclean.leader.election.enable'和'auto.leader.rebalance.enable'。
>> - 关于数据留存的参数：'log.retention.{hours|minutes|ms}'、'log.retention.bytes'和'message.max.bytes'.


再次强调一下，今天我和你分享的所有参数都是那些要修改默认值的参数，因为它们的默认值不适合一般的生产环境。当然，我并不是说其他 100 多个参数就不重要。事实上，在专栏的后面我们还会陆续提到其他的一些参数，特别是那些和性能息息相关的参数。所以今天我提到的所有参数，我希望作为一个最佳实践给到你，可以有的放矢地帮助你规划和调整你的 Kafka 生产环境。


## 如何配置Topic、JVM和操作系统参数

> Topic级别参数
>> - 'retention.ms'：规定了该Topic消息被保存的时长。'retention.bytes'：规定了要为该Topic预留多大的磁盘空间。
>> - 'max.message.bytes'：它决定了Kafka Broker能够正常接收该Topic的最大消息大小。

> JVM参数
>> - 'KAFKA_HEAP_OPTS'：指定堆大小。
>> - 'KAFKA_JVM_PERFORMANCE_OPTS'：指定GC参数。

> 操作系统参数
>> - 文件描述符限制。
>> - 文件系统类型。
>> - Swappiness.
>> - 提交时间。

今天我和你分享了关于 Kafka 集群设置的各类配置，包括 Topic 级别参数、JVM 参数以及操作系统参数，连同上一篇一起构成了完整的 Kafka 参数配置列表。我希望这些最佳实践能够在你搭建 Kafka 集群时助你一臂之力，但切记配置因环境而异，一定要结合自身业务需要以及具体的测试来验证它们的有效性。

