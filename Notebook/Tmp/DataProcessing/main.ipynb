{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、背景：车端会采集整车数据到云端做分析，采集的动作是车端计算引擎实施，车端计算引擎的输入是JSON配置文件<u>（JSON配置文件由算子、信号等构成一系列触发规则）</u>，为确保车端计算引擎可支持正确按配置文件执行，通常会做模拟测试：\n",
    "\n",
    "2、模拟测试说明：模拟JSON配置文件策略（策略需支持28+算子，信号1000+），模拟时需保策略的完备性、尽可能覆盖所有场景，充分保证车型可按照配置文件正确上报；\n",
    "\n",
    "JSON策略例如：\n",
    "- 1、A信号由非2跳变到2且A连续三帧=2同时B由非2跳变到2且B连续三帧=2\n",
    "- 2、A=1持续6帧且该信号告警标志位置于FALSE，触发告警\n",
    "- 3、A=5，且持续时长>15s，且当前告警标志位为FALSE\n",
    "\n",
    "车端算子举例：Filter，Downsample，Dynamize，Splitter，Expand，Project，StreamAggregate，Hopping Window，Pattern Window\n",
    "\n",
    "![车端算子举例](WechatIMG40.jpg)\n",
    "\n",
    "3、要求：通过模型，自动生成配置文件的数据采集策略，以及一段时间的测试数据，期望在较低代价的情况下（非穷举方法），保证生成的采集策略尽可能完备；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、开始建模分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1、算子类、信号类定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 车端计算引擎的输入是JSON配置文件（JSON配置文件由算子、信号等构成一系列触发规则），为确保车端计算引擎可支持正确按配置文件执行，通常会做模拟测试：\n",
    "\n",
    "# 定义算子类\n",
    "class Operator:\n",
    "    def __init__(self, name, description):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "\n",
    "# 定义信号类\n",
    "class Signal:\n",
    "    def __init__(self, name, value_range):\n",
    "        self.name = name\n",
    "        self.value_range = value_range\n",
    "\n",
    "# 定义算子\n",
    "operators = [\n",
    "    Operator('Filter', '基于条件过滤信号'),\n",
    "    Operator('Downsample', '消减信号的采样'),\n",
    "    Operator('Dynamize', '算子将数据中含空值的行去除，可以指定检查列'),\n",
    "    Operator('Splitter', '将信号拆分为多个流'),\n",
    "    Operator('Expand', ''),\n",
    "    Operator('Project', ''),\n",
    "    Operator('StreamAggregate', ''),\n",
    "    Operator('HoppingWindow', '跳跃滑动窗口'),\n",
    "    Operator('PatternWindow', '模式匹配窗口')\n",
    "]\n",
    "\n",
    "# 定义信号, 后续信号可扩展到1000+，示例为3种不同类型的信号\n",
    "signals = [\n",
    "    Signal('A', (1, 10)),  # 整型信号\n",
    "    Signal('B', (0.0, 10.0)),  # 浮点型信号\n",
    "    Signal('C', (True, False)),  # 布尔型信号\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2、构造数据输入（车端计算引擎的输入是JSON配置文件）\n",
    "生成的策略需要覆盖以下方面：\n",
    "- **信号触发条件**：每个信号的触发条件（如某值持续时间、跳变等）。\n",
    "- **算子组合**：对信号的算子处理（如Filter, Downsample等）。\n",
    "- **触发规则**：多信号组合条件下的复杂触发规则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# 生成随机整数\n",
    "def generate_random_int(value_range):\n",
    "    return random.randint(value_range[0], value_range[1])\n",
    "\n",
    "# 生成随机浮点数\n",
    "def generate_random_float(value_range):\n",
    "    return random.uniform(value_range[0], value_range[1])\n",
    "\n",
    "# 生成随机布尔值\n",
    "def generate_random_bool():\n",
    "    return random.choice([True, False])\n",
    "\n",
    "# 生成随机测试数据\n",
    "def generate_test_data(signal, length):\n",
    "    data = []\n",
    "    for _ in range(length):\n",
    "        if type(signal.value_range[0]) == int:\n",
    "            data.append(generate_random_int(signal.value_range))\n",
    "        elif type(signal.value_range[0]) == float:\n",
    "            data.append(generate_random_float(signal.value_range))\n",
    "        elif type(signal.value_range[0]) == bool:\n",
    "            data.append(generate_random_bool())\n",
    "        else:\n",
    "            pass\n",
    "    return data\n",
    "\n",
    "def generate_signal_sequence(signal, length, jump_probability=0.2):\n",
    "    # 生成一个特定信号的时间序列，包含信号随机跳变\n",
    "    sequence = []\n",
    "    current_value = generate_test_data(signal, length)\n",
    "    # print(generate_test_data(signal, length))\n",
    "    for _ in range(length):\n",
    "        if random.random() < jump_probability:    # 信号随机跳变\n",
    "            current_value = generate_test_data(signal, length)\n",
    "        sequence.append(current_value)\n",
    "    return sequence\n",
    "\n",
    "# 测试模拟数据\n",
    "def simulate_test_data(num_samples=100, sequence_length=10):\n",
    "    test_data = []\n",
    "    signal_list = [random.choice(signals) for _ in range(num_samples)]\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        data_point = {}\n",
    "        for signal in signal_list:\n",
    "            sequence = generate_signal_sequence(signal, sequence_length)\n",
    "            # print(sequence)\n",
    "            data_point[signal.name] = sequence\n",
    "        test_data.append(data_point)\n",
    "    \n",
    "    return test_data\n",
    "\n",
    "# 单测：输出构造的信号\n",
    "simulate_test_data(4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、模型的构建及运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1、 模型构建（强化学习生成策略）\n",
    "采用强化学习的方法，模型可以通过不断尝试生成不同的策略来优化其有效性和完备性。\n",
    "- **状态空间**：当前配置的状态（如信号的状态，算子配置等）。\n",
    "- **动作空间**：生成或修改一条新的策略规则。\n",
    "- **奖励机制**：对每个生成的策略进行模拟测试，评价其完备性和有效性，给予对应的奖励。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(True) == int(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_condition(data_point, condition):\n",
    "    # print(data_point, condition)\n",
    "    \"\"\"检查单个数据点是否满足条件，例如 'A=2'\"\"\"\n",
    "    signal, expected_value = condition.split(\"=\")\n",
    "    try:\n",
    "        res = 0.0\n",
    "        total = 0.0\n",
    "        for point_list in data_point.get(signal):\n",
    "            total += len(point_list)\n",
    "            \n",
    "            for signal_value in point_list:\n",
    "                if (int(signal_value) == int(expected_value)):\n",
    "                    res += 1.0\n",
    "    except:\n",
    "        print(condition, signal_value, expected_value)\n",
    "    return res / total\n",
    "\n",
    "def calculate_coverage(strategy, test_data):\n",
    "    \"\"\"计算策略的覆盖率，即策略在测试数据中触发的比例\"\"\"\n",
    "    covered_points = sum(\n",
    "        all(check_condition(data_point, rule[\"condition\"]) for rule in strategy)\n",
    "        for data_point in test_data\n",
    "    )\n",
    "    return covered_points / len(test_data)\n",
    "\n",
    "# 定义奖励函数（以策略覆盖率作为奖励）\n",
    "def reward_function(strategy, test_data):\n",
    "    coverage = calculate_coverage(strategy, test_data)\n",
    "    return coverage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. 模型运行测试和优化\n",
    "- **模型测试覆盖率评估**：计算生成策略在测试数据中的触发情况和覆盖率。\n",
    "\n",
    "- **策略优化**：根据测试结果，通过调整生成策略的模型参数，逐步优化生成的策略，提高其完备性和有效性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 413.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B=4.858653588784955 2.506385908016442 4.858653588784955\n",
      "B=4.858653588784955 9.939266348258881 4.858653588784955\n",
      "B=4.858653588784955 1.6383849454037813 4.858653588784955\n",
      "B=4.858653588784955 6.18283963781244 4.858653588784955\n",
      "B=4.858653588784955 3.758815795454684 4.858653588784955\n",
      "B=4.858653588784955 3.931437148570006 4.858653588784955\n",
      "B=4.858653588784955 6.072572818239649 4.858653588784955\n",
      "B=4.858653588784955 5.542116175016777 4.858653588784955\n",
      "B=4.858653588784955 6.849884402837309 4.858653588784955\n",
      "B=4.858653588784955 2.382751023789883 4.858653588784955\n",
      "C=False False False\n",
      "C=False False False\n",
      "C=False True False\n",
      "C=False True False\n",
      "C=False False False\n",
      "C=False False False\n",
      "C=False True False\n",
      "C=False True False\n",
      "C=False False False\n",
      "C=False False False\n",
      "Best Strategy: [\n",
      "    {\n",
      "        \"operator\": \"PatternWindow\",\n",
      "        \"condition\": \"B=4.858653588784955\"\n",
      "    },\n",
      "    {\n",
      "        \"operator\": \"HoppingWindow\",\n",
      "        \"condition\": \"C=True\"\n",
      "    }\n",
      "]\n",
      "Best Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 强化学习策略生成\n",
    "def generate_strategy(strategy_nums=10):\n",
    "    strategy = []\n",
    "    for _ in range(random.randint(1, 10)): # 随机生成1到10条策略规则\n",
    "        signal = random.choice([random.choice(signals) for _ in range(strategy_nums)])\n",
    "        operator = random.choice([random.choice(operators) for _ in range(strategy_nums)])\n",
    "        # print(operators)\n",
    "        condition = f\"{signal.name}={random.randint(1, 5)}\" \n",
    "        # 假设条件为A~C信号值的简单比较\n",
    "        if type(signal.value_range[0]) == int:\n",
    "            condition = f\"{signal.name}={generate_random_int(signal.value_range)}\" \n",
    "        elif type(signal.value_range[0]) == float:\n",
    "            condition = f\"{signal.name}={generate_random_float(signal.value_range)}\"\n",
    "        elif type(signal.value_range[0]) == bool:\n",
    "            condition = f\"{signal.name}={generate_random_bool()}\"\n",
    "        else:\n",
    "            pass\n",
    "        strategy.append({\n",
    "            \"operator\": operator.name,\n",
    "            \"condition\": condition\n",
    "        })\n",
    "    return strategy\n",
    "\n",
    "# 评估策略\n",
    "def evaluate_strategy(strategy):\n",
    "    test_data = simulate_test_data(10, 10)\n",
    "    # print(test_data)\n",
    "    return reward_function(strategy, test_data)\n",
    "\n",
    "# main 模型函数入口\n",
    "best_strategy = {}\n",
    "best_reward = -float('inf')\n",
    "for _ in tqdm(range(2)): # 迭代2024次\n",
    "    strategy = generate_strategy(3)\n",
    "    reward = evaluate_strategy(strategy)\n",
    "    # print(f\"策略：{strategy} ---> 覆盖率分数（奖励函数输出）{reward}\")\n",
    "    if reward > best_reward:\n",
    "        best_strategy = strategy\n",
    "        best_reward = reward\n",
    "\n",
    "# 输出最佳策略\n",
    "print(\"Best Strategy:\", json.dumps(best_strategy, indent=4))\n",
    "print(\"Best Reward:\", best_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上述强化学习的方式，可以生成并动态优化数据采集策略，确保在各种测试数据场景下的策略有效性和完备性，避免穷举法带来的时间复杂度。</br>\n",
    "后续优化方向有如下三点：\n",
    "- 优化数据采集的策略，可以引入遗传算法或更复杂的强化学习模型（如深度Q学习：DQN）自动学习最优的数据采集行为；\n",
    "- 优化策略生成函数generate_strategy，更符合模拟信号策略的真实数据，确保生成的策略在实际应用中的有效性；\n",
    "- 优化奖励函数reward_function，更精确地衡量策略的完备性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
